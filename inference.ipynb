{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the inference notebook for the Urban Sound Classification project (NAML-2024 project by Lorenzo Gentile).\n",
    "This notebook lets you load trained models to make predictions on the test set. You can also plot the confusion matrix and inspect the feature of intermediate layers of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load one of the available trained models from the SAVED_MODELS_DIR directory. \n",
    "The notebook will prompt you to select the model you want to load. Along with the model, also the parameters used for loading and preprocessing the data and those used for training the model will be loaded. In this way, you can reproduce the same preprocessing steps and use a test set that is consistent with the one used for training (the model has not trained on samples from the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODELS_DIR = 'saved_models/'\n",
    "\n",
    "from scripts.model_utils import list_and_load_model\n",
    "\n",
    "# Load a model\n",
    "model, preprocess_params, training_params = list_and_load_model(SAVED_MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we unpack and print the preprocessing parameters and the training parameters, which were saved in JSON format in the assets directory of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"Preprocess parameters:\")\n",
    "pprint(preprocess_params, sort_dicts=False)\n",
    "\n",
    "print(\"\\nTraining parameters:\")\n",
    "pprint(training_params, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we load the dataset on which the model was trained and we apply the exact same preprocessing steps. Then we split the dataset to obtain the test set (which thanks to the reproducibility of the preprocessing steps is consistent with the one used for training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataset_loading import load_dataset\n",
    "from scripts.audio_preprocessing import apply_resizing, transform_normalize_dataset\n",
    "\n",
    "# Load and process audio files with same configuration\n",
    "\n",
    "batch_size = training_params['BATCH_SIZE']\n",
    "\n",
    "_, test_ds, class_names = load_dataset(preprocess_params)\n",
    "\n",
    "if preprocess_params['DATASET_NAME'] == 'UrbanSound8K':\n",
    "    test_ds = apply_resizing(test_ds, preprocess_params)\n",
    "test_ds = transform_normalize_dataset(test_ds, preprocess_params)\n",
    "test_ds = test_ds.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, you can plot the confusion matrix of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model_utils import print_confusion_matrix\n",
    "\n",
    "# Print the confusion matrix\n",
    "print_confusion_matrix(model, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, you can inspect the feature maps of the intermediate layers of the model. You can select the layer you want to inspect from the dropdown menu. You can additionally pass a seed as last argument to change the input sample used for the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model_utils import plot_feature_maps\n",
    "\n",
    "plot_feature_maps(model, test_ds, class_names, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in this cell, you can visualize the filters of the convolutional layers of the model. Filters of all convolutional layers are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model_utils import plot_conv_weights\n",
    "\n",
    "# Visualize the convolutional weights\n",
    "plot_conv_weights(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env_stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
